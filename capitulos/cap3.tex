% !TEX root = ../main.tex
\documentclass[../main.tex]{subfiles}

\chapter{Aprendizaje con Kernels}

\begin{quotation}

Alza del hiperparametro origina nueva alza del hiperparametro \\
Alza de los errores \\
Provoca instantáneamente la duplicación de los errores \\
Alza de las métricas \\
Origina alza de las métricas.
\NC{Poner algo profundo por el estilo. (?)}

\end{quotation}

\section{Introducción}

Un kernel es una función simétrica y definida positiva $k(\cdot,\cdot)$ que
puede ser entendida como una medida de similitud entre los argumentos que opera.
En el siguiente capítulo, se definen estos objetos matemáticos de manera formal,
se investigan sus características y se derivan algunos métodos del aprendizaje
de máquinas que toman ventaja sus propiedades.

\section{Terminología y propiedades}

El término \textbf{kernel} proviene del estudio de operadores integrales en el
campo del análisis funcional. En tal contexto se les identifica como aquellas
funciones $k$ que determinan un operador $T_k$ a través de:
\begin{equation}
    (T_k f) (x) = \int_{\mathcal{X}} k(x,x') f(x') dx
\end{equation}

En concordancia con la perspectiva que se desea abarcar, se denotará como kernel
a toda función $k: \mathcal{X} \times \mathcal{X} \rightarrow \mathbb{R}$ en el
espacio de características \footnote{El codominio del kernel $k$ no tiene por que
restringirse a los reales, para ciertas aplicaciones puede ser conviene utilizar
los complejos. En general las propiedades de interés se preservan en ambos cuerpos,
por lo que por simplicidad se considera solo el caso real en esta monografía.}.
Dentro de tal clase de funciones, son de importancia a aquellas capaces de ``generalizar"
el concepto de \textit{porducto interno}, el \index{Teorema de Mercer}
\textbf{Teorema de Mercer} permite identificar tal subconjunto.
\NC{Agregar apendice sobre Teoria de Medida + integrar respecto a una medida
learning with Kernels}
\begin{theorem}[Teorema de Mercer]
\label{mercer}
Sea $(\mathcal{X},\mu)$ un espacio de medida finita y $k \in L_{\infty}(\mathcal{X}^2)$
una función real y simétrica, tal que el operador integral:

\begin{gather}
    \begin{aligned}
        T_k &: L_{2}(\mathcal{X}) \rightarrow L_{2}(\mathcal{X}) \\
        (T_k f) (x) &:= \int_{\mathcal{X}} k(x,x') f(x') d\mu(x')
    \end{aligned}
\end{gather}

es semidefinido positivo, es decir, para toda $f \in L_{2}(\mathcal{X})$ se cumple:
\begin{equation}
    \int_{\mathcal{X}^2} k(x,x') f(x) f(x') d\mu(x) d\mu(x') \geq 0
\end{equation}

Si $\psi_j \in L_2(\mathcal{X})$ son las funciones propias ortonormales de $T_f$
asociadas a los valores propios $\lambda_j > 0$, ordenados de manera decreciente.
Entonces,
\begin{enumerate}
    \item $(\lambda_j)_j \in l_1$
    \item $k(x,x')=\sum_{j=1}^{N_{\mathcal{H}}} \lambda_j \psi_j(x)\psi_j(x')$
    se cumple para casi todos los elementos $x,x' \in \mathcal{X}$. Además $N_{\mathcal{H}} \in \mathbb{N}$
    o $N_{\mathcal{H}} = \infty$, en este último caso, la serie respectiva converge
    absoluta y uniformemente para casi todos los elementos $x,x' \in \mathcal{X}$.
\end{enumerate}

\end{theorem}

La segunda implicación del teorema anterior, permite construir una aplicación
$\Phi: \mathcal{X} ~ &\rightarrow ~ l_2^{N_{\mathcal{H}}}$ tal que
$x ~ &\mapsto ~ (\sqrt{\lambda_j} \psi_j(x))_{j=1,\ldots,N_{\mathcal{H}}}$, es decir,
a cada elemento de $\mathcal{X}$ se le asocia una transformación por medio de las
funciones propias asociadas a $k(\cdot,\cdot)$ al espacio $l_2^{N_{\mathcal{H}}}$.
Este último espacio esta provisto de producto interno, por lo que es posible expresar
$k(x,x') = \langle  \Phi(x), \Phi(x') \rangle_{l_2^{N_{\mathcal{H}}}}$ para casi todo $x \in \mathcal{X}$.
Esto permite interpretar a $\Phi$ como una aplicación a un espacio de \textit{características},
más aún, en este espacio $k(\cdot,\cdot)$ actúa como un producto interno, esto se
concreta en el siguiente teorema.


\begin{theorem}[Aplicación kernel de Mercer]
\label{mercer_app}
Si $k$ es un kernel que cumple las condiciones del teorema (\ref{mercer}), se
puede construir una aplicación $\Phi$ a un espacio donde $k$ se comporta
como un producto interno:
\begin{equation*}
    k(x,x') = \langle \Phi(x), \Phi(x') \rangle
\end{equation*}
para casi todo $x,x' \in \mathcal{X}$. Más aún, para todo $\varepsilon >0$, existe
una aplicación $\Phi_{n}$ a un espacio $n-$dimensional con producto interno tal que
\begin{equation*}
    |k(x,x') - \langle \Phi_{n}(x), \Phi_{n}(x') \rangle| < \varepsilon
\end{equation*}
para casi todo $x,x' \in \mathcal{X}$.
\end{theorem}

La convergencia uniforme en el teorema anterior implica que para cualquier precisión
$\varepsilon >0$, debe existir un $n \in \mathbb{N}$ tal que $k$ puede ser aproximado
como un producto interno en $\mathbb{R}^{n}$. Lo anterior se observa al notar que
para casi todo $x,x' \in \mathcal{X}$, se tiene $|k(x,x') - \langle \Phi^{n}(x), \Phi^{n}(x') \rangle| < \varepsilon$,
donde $ \Phi^{n}(x): x \mapsto (\sqrt{\lambda_1}\psi_1(x), \ldots,\sqrt{\lambda_n}\psi_n(x))$.
En tal contexto, se puede interpretar al espacio de características como un espacio
finito dimensional dentro de cierta precisión $\varepsilon$. Esta característica
es una parte esencial en el aprendizaje con kernels y dará lugar a la técnica
conocida como \textit{truco del kernel}.

La condición de simetría para $k(\cdot, \cdot)$, necesaria en el teorema (\ref{mercer}),
permite dotar de esta propiedad al producto interno definido en (\ref{mercer_app}).
Por otra parte, es necesario caracterizar la positividad de $k(\cdot, \cdot)$ de
manera tal que se pueda contextualizar dentro del aprendizaje de máquinas, para ello
se utiliza la noción de matriz de \textbf{Gram}.

\toLatex{3.png}

Esta noción, permite definir la positividad de un kernel $k(\cdot,\cdot)$
en función de las propiedades que sus matrices de Gram poseen, en este sentido,
el concepto de \textbf{matriz semidefinida} juega un rol fundamental.

\toLatex{1.png}

Dentro de las propiedades de este tipo de matrices se encuentra la siguiente proposición:

\toLatex{2.png}

Finalmente, se podrá caracterizar la positividad de un kernel $k(\cdot, \cdot)$
mediante la siguiente proposición:

\toLatex{4.png}

En particular, esto significa que cualquier función simétrica y semidefinida
positiva, acepta una descomposición por medio del teorema de Mercer y por tanto
induce una transformación $\Phi$ a un espacio de características (posiblemente
de dimensión infinita, $N_{\mathcal{H}}=\infty$) donde actúa como un producto interno.
Si por otra parte, se posee una transformación $\Phi: \mathcal{X} \rightarrow \mathcal{H}$,
donde $\mathcal{H}$ es un espacio con producto interno, es posible construir un
kernel por medio de $k(x,x')=\langle \Phi(x), \Phi(x') \rangle_{\mathcal{H}}$.
Este es por definición, simétrico (lo hereda del producto interno) y además cumple:

\toLatex{5.png}

Por tanto será semidefindo positivo y finalmente un kernel que cumple las condiciones
del teorema (\ref{mercer}). Esto permite modelar kernels por medio de transformaciones
conocidas, a la vez que permite asumir la existencia de una transformación dado un kernel.

\section{Espacios de Hilbert con kernel reproductor - RKHS}

Hasta este punto, se puede entender un kernel como una función semidefinida positiva
y simétrica compatible con una representación, ya sea implícita o explicita,
de un espacio inicial $\mathcal{X}$ en un espacio con producto interno (o \textit{pre-Hilbertiano}).
El propósito de esta sección corresponde a estudiar las características de este espacio
con el fin de obtener herramientas para el uso de kernels en tareas de aproximación
de funciones.

\toLatex{6.png}

Por definición (punto 2), un RKHS es un espacio formado por combinaciones lineales
de funciones de la forma $k_{x}(\cdot)$ para todo $x \in \mathcal{X}$ y sus funciones
limite (clausura). Esto último quiere decir, que toda función $f \in \matchal{H}$
puede ser aproximada a través de sucesiones de combinaciones lineales de elementos
de la forma $k_{x}(\cdot)$, que claramente están unicamente determinados por el
kernel $k(\cdot, \cdot)$.

Por su parte, la propiedad de reproducción (punto 1), se puede comprender al observar
que para todo $f \in \mathcal{H}$, espacio RKHS correspondiente al kernel $k(\cdot, \cdot)$,
es posible escribir $f$ como:
\begin{equation}
    f(\cdot) = \sum_{i = 1}^{\infty} \alpha_i k(x_i, \cdot)
\end{equation}




Que por el teorema de Mercer verifica:
\begin{equation}
    f(x) = \sum_{i = 1}^{\infty} \alpha_i \sum_{j = 1}^{N_{\mathcal{H}}} \lambda_j \psi_j(x_i)\psi_j(x)
\end{equation}
